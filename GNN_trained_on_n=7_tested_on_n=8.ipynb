{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "555321d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e182f4",
   "metadata": {},
   "source": [
    "# Data Preparation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8df3016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adjacency_matrices(df):\n",
    "    df['adjacency_matrix'] = None\n",
    "    # Step 3: Iterate through Rows and Populate the New Column\n",
    "    for index, row in df.iterrows(): \n",
    "        # Convert String to a real list !\n",
    "        edges = ast.literal_eval(row['edges'])\n",
    "        # Determine the number of nodes\n",
    "        num_nodes = max(max(edge) for edge in edges) + 1\n",
    "        # Create an empty adjacency matrix\n",
    "        adjacency_matrix = np.zeros((num_nodes, num_nodes), dtype=int)\n",
    "        # Fill the adjacency matrix based on the edges\n",
    "        for edge in edges:\n",
    "            adjacency_matrix[edge[0], edge[1]] = 1\n",
    "            adjacency_matrix[edge[1], edge[0]] = 1  # Assuming the graph is undirected\n",
    "\n",
    "        # Assign the adjacency matrix to the new column\n",
    "        df.at[index, 'adjacency_matrix'] = adjacency_matrix\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d095ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transform_DictEdges_to_ArrayEdges(d):\n",
    "    d = ast.literal_eval(d) \n",
    "    max_key = max(d.keys())\n",
    "    result_array = [0] * (max_key + 1)\n",
    "    for key, value in d.items():\n",
    "        result_array[key] = value\n",
    "    return result_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704da61c",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5021c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding_matrix(matrix,padding_position):\n",
    "    n = len(matrix)\n",
    "    padded_row = np.zeros((1, n))\n",
    "    padded_col = np.zeros((n+1, 1))\n",
    "\n",
    "    # Insert padded row at specified position\n",
    "    matrix = np.concatenate((matrix[:padding_position], padded_row, matrix[padding_position:]), axis=0)\n",
    "    \n",
    "    # Insert padded column at specified position\n",
    "    matrix = np.concatenate((matrix[:, :padding_position], padded_col, matrix[:, padding_position:]), axis=1)\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6cf2190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding_array(array, position):\n",
    "    return np.insert(array, position, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e485184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding_to_dataframe(dataset, n):\n",
    "    for index, row in dataset.iterrows():\n",
    "        padding_position = np.random.randint(0, n)\n",
    "        dataset.at[index, 'adjacency_matrix'] = add_padding_matrix(row['adjacency_matrix'], padding_position)\n",
    "        dataset.at[index, 'node_assignment_array'] = add_padding_array(row['node_assignment_array'], padding_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33726e9",
   "metadata": {},
   "source": [
    "## Apply Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec23bdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the File \n",
    "df = pd.read_csv('Data_n_equal_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6e01f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_adjacency_matrices(df)\n",
    "# Convert dictionary values to list\n",
    "df['node_assignment_array'] = df['node_assignment'].apply(lambda x: Transform_DictEdges_to_ArrayEdges(x))\n",
    "add_padding_to_dataframe(df,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae24e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split Data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(df['adjacency_matrix'].values, df['node_assignment_array'].values, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dd61939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train.tolist()).astype('float32')\n",
    "y_train = np.array(y_train.tolist()).astype('float32')\n",
    "X_val = np.array(X_val.tolist()).astype('float32')\n",
    "y_val = np.array(y_val.tolist()).astype('float32')\n",
    "X_test = np.array(X_test.tolist()).astype('float32')\n",
    "y_test = np.array(y_test.tolist()).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a71ffb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(597, 8, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22183116",
   "metadata": {},
   "source": [
    "# Build the GNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bb5ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GNN model\n",
    "class GNN(Model):\n",
    "    def __init__(self):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = layers.Conv1D(16, 1, activation='relu')  # Convolutional layer\n",
    "        self.conv1 = layers.Conv1D(32, 3, activation='relu')  # Convolutional layer\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense1 = layers.Dense(64, activation='relu')  # Dense layer\n",
    "        self.dense2 = layers.Dense(8)  # Output layer with 8 units\n",
    "        self.built = True  # Set model as built\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c64d36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1 (Conv1D)           multiple                  800       \n",
      "                                                                 \n",
      " flatten (Flatten)           multiple                  0         \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  12352     \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13672 (53.41 KB)\n",
      "Trainable params: 13672 (53.41 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/70\n",
      "19/19 [==============================] - 1s 13ms/step - loss: 0.7484 - val_loss: 0.5880\n",
      "Epoch 2/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5678 - val_loss: 0.5167\n",
      "Epoch 3/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4905 - val_loss: 0.4649\n",
      "Epoch 4/70\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4374 - val_loss: 0.4325\n",
      "Epoch 5/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4062 - val_loss: 0.4077\n",
      "Epoch 6/70\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.3941\n",
      "Epoch 7/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3668 - val_loss: 0.3885\n",
      "Epoch 8/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3532 - val_loss: 0.3808\n",
      "Epoch 9/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3406 - val_loss: 0.3735\n",
      "Epoch 10/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3289 - val_loss: 0.3701\n",
      "Epoch 11/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3187 - val_loss: 0.3685\n",
      "Epoch 12/70\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3116 - val_loss: 0.3670\n",
      "Epoch 13/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3642\n",
      "Epoch 14/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2940 - val_loss: 0.3575\n",
      "Epoch 15/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2868 - val_loss: 0.3584\n",
      "Epoch 16/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2805 - val_loss: 0.3568\n",
      "Epoch 17/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2741 - val_loss: 0.3515\n",
      "Epoch 18/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2683 - val_loss: 0.3600\n",
      "Epoch 19/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2592 - val_loss: 0.3513\n",
      "Epoch 20/70\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2543 - val_loss: 0.3506\n",
      "Epoch 21/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2474 - val_loss: 0.3528\n",
      "Epoch 22/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2423 - val_loss: 0.3463\n",
      "Epoch 23/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2352 - val_loss: 0.3490\n",
      "Epoch 24/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2346 - val_loss: 0.3484\n",
      "Epoch 25/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2270 - val_loss: 0.3508\n",
      "Epoch 26/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2210 - val_loss: 0.3531\n",
      "Epoch 27/70\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2172 - val_loss: 0.3504\n",
      "Epoch 28/70\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2132 - val_loss: 0.3436\n",
      "Epoch 29/70\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2076 - val_loss: 0.3479\n",
      "Epoch 30/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2047 - val_loss: 0.3492\n",
      "Epoch 31/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1996 - val_loss: 0.3484\n",
      "Epoch 32/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1974 - val_loss: 0.3422\n",
      "Epoch 33/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1920 - val_loss: 0.3480\n",
      "Epoch 34/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1913 - val_loss: 0.3421\n",
      "Epoch 35/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1861 - val_loss: 0.3521\n",
      "Epoch 36/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1821 - val_loss: 0.3501\n",
      "Epoch 37/70\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1778 - val_loss: 0.3476\n",
      "Epoch 38/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1752 - val_loss: 0.3476\n",
      "Epoch 39/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1710 - val_loss: 0.3523\n",
      "Epoch 40/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1698 - val_loss: 0.3507\n",
      "Epoch 41/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1665 - val_loss: 0.3467\n",
      "Epoch 42/70\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1673 - val_loss: 0.3472\n",
      "Epoch 43/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1652 - val_loss: 0.3585\n",
      "Epoch 44/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1602 - val_loss: 0.3556\n",
      "Epoch 45/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1545 - val_loss: 0.3531\n",
      "Epoch 46/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.3486\n",
      "Epoch 47/70\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.3503\n",
      "Epoch 48/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1475 - val_loss: 0.3543\n",
      "Epoch 49/70\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1462 - val_loss: 0.3574\n",
      "Epoch 50/70\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1433 - val_loss: 0.3498\n",
      "Epoch 51/70\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.1401 - val_loss: 0.3542\n",
      "Epoch 52/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1386 - val_loss: 0.3505\n",
      "Epoch 53/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1363 - val_loss: 0.3550\n",
      "Epoch 54/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1333 - val_loss: 0.3543\n",
      "Epoch 55/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1326 - val_loss: 0.3591\n",
      "Epoch 56/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1314 - val_loss: 0.3585\n",
      "Epoch 57/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1280 - val_loss: 0.3557\n",
      "Epoch 58/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1264 - val_loss: 0.3537\n",
      "Epoch 59/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1240 - val_loss: 0.3550\n",
      "Epoch 60/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1218 - val_loss: 0.3552\n",
      "Epoch 61/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1206 - val_loss: 0.3559\n",
      "Epoch 62/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1190 - val_loss: 0.3581\n",
      "Epoch 63/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1162 - val_loss: 0.3591\n",
      "Epoch 64/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1165 - val_loss: 0.3630\n",
      "Epoch 65/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1136 - val_loss: 0.3679\n",
      "Epoch 66/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1135 - val_loss: 0.3588\n",
      "Epoch 67/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1117 - val_loss: 0.3675\n",
      "Epoch 68/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1114 - val_loss: 0.3715\n",
      "Epoch 69/70\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1085 - val_loss: 0.3582\n",
      "Epoch 70/70\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1057 - val_loss: 0.3656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22d23bb0700>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = GNN()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mse')  # Using Mean Squared Error loss for regression task\n",
    "\n",
    "# Print model summary\n",
    "model.build((None, 8, 8))  # Manually build the model with input shape\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=70,validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b96cb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model \n",
    "loss = model.evaluate(X_train, y_train)\n",
    "print(\"Average Loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e286182",
   "metadata": {},
   "source": [
    "# Predict on X and y of n equal to 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a6abab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8 = pd.read_csv('datacvxpy8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d879a0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>edges</th>\n",
       "      <th>node_assignment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>[(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6...</td>\n",
       "      <td>[1, 1, 1, 1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>[(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6...</td>\n",
       "      <td>[1, 1, 1, 1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>[(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6...</td>\n",
       "      <td>[1, 1, 1, 1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>[(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6...</td>\n",
       "      <td>[1, 1, 1, 1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>[(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6...</td>\n",
       "      <td>[1, 1, 1, 1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>8</td>\n",
       "      <td>[(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6...</td>\n",
       "      <td>[1, 1, 1, -1, -1, 1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>8</td>\n",
       "      <td>[(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6...</td>\n",
       "      <td>[1, 1, 1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>8</td>\n",
       "      <td>[(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6...</td>\n",
       "      <td>[1, 1, -1, -1, -1, -1, -1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>8</td>\n",
       "      <td>[(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6...</td>\n",
       "      <td>[1, 1, 1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>8</td>\n",
       "      <td>[(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6...</td>\n",
       "      <td>[1, 1, 1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     n                                              edges  \\\n",
       "0    8  [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6...   \n",
       "1    8  [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6...   \n",
       "2    8  [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6...   \n",
       "3    8  [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6...   \n",
       "4    8  [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6...   \n",
       "..  ..                                                ...   \n",
       "463  8  [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6...   \n",
       "464  8  [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6...   \n",
       "465  8  [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6...   \n",
       "466  8  [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6...   \n",
       "467  8  [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6...   \n",
       "\n",
       "                   node_assignment  \n",
       "0     [1, 1, 1, 1, -1, -1, -1, -1]  \n",
       "1     [1, 1, 1, 1, -1, -1, -1, -1]  \n",
       "2     [1, 1, 1, 1, -1, -1, -1, -1]  \n",
       "3     [1, 1, 1, 1, -1, -1, -1, -1]  \n",
       "4     [1, 1, 1, 1, -1, -1, -1, -1]  \n",
       "..                             ...  \n",
       "463   [1, 1, 1, -1, -1, 1, -1, -1]  \n",
       "464  [1, 1, 1, -1, -1, -1, -1, -1]  \n",
       "465  [1, 1, -1, -1, -1, -1, -1, 1]  \n",
       "466  [1, 1, 1, -1, -1, -1, -1, -1]  \n",
       "467  [1, 1, 1, -1, -1, -1, -1, -1]  \n",
       "\n",
       "[468 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09bc1a52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_adjacency_matrices(df_8)\n",
    "df_8['node_assignment'] = df_8['node_assignment'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a26e4c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_8['adjacency_matrix'].values\n",
    "y=df_8['node_assignment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "730b3773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays\n",
    "X = np.array(X.tolist()).astype('float32')\n",
    "y = np.array(y.tolist()).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "166ec3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Define the threshold\n",
    "threshold = 0.0  \n",
    "\n",
    "# Apply the threshold to the predictions\n",
    "binary_predictions = np.where(predictions > threshold, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aec4e3b",
   "metadata": {},
   "source": [
    "# Strict Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55383f1d",
   "metadata": {},
   "source": [
    "Strict accuracy is a metric that measures the percentage of predictions that match the true values exactly. In other words, it evaluates whether all elements of a prediction match the corresponding elements of the true values. For example, if a prediction array [1, 0, 1, 1] is compared to the true array [1, 0, 1, 1], strict accuracy would be 1 (or 100%), indicating that the prediction is entirely correct. However, if any element of the prediction mismatches the true value, strict accuracy would be 0 (or 0%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "72908f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_strict_accuracy(binary_predictions, y):\n",
    "    \"\"\"\n",
    "    Calculate strict accuracy between binary predictions and true values.\n",
    "\n",
    "    Args:\n",
    "        binary_predictions (list of arrays): List of binary predictions.\n",
    "        y (list of arrays): List of true values.\n",
    "\n",
    "    Returns:\n",
    "        float: Strict accuracy.\n",
    "    \"\"\"\n",
    "    count_matches = 0\n",
    "    count_unmatches = 0\n",
    "\n",
    "    for i in range(len(binary_predictions)):\n",
    "        # Convert to numpy arrays if not already\n",
    "        binary_prediction_arr = np.array(binary_predictions[i])\n",
    "        y_arr = np.array(y[i])\n",
    "        \n",
    "        # Check if the elements are equal\n",
    "        if np.array_equal(binary_prediction_arr, y_arr):\n",
    "            count_matches += 1\n",
    "        else:\n",
    "            count_unmatches += 1\n",
    "    # Calculate strict accuracy\n",
    "    strict_accuracy = count_matches / (count_matches + count_unmatches) if (count_matches + count_unmatches) > 0 else 0\n",
    "    \n",
    "    return strict_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "077c9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "strict_accuracy=calculate_strict_accuracy(binary_predictions,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39b300bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41025641025641024"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strict_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26a97ae",
   "metadata": {},
   "source": [
    "# Average Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b2628e",
   "metadata": {},
   "source": [
    " Average accuracy, on the other hand, calculates the accuracy for eachindividual prediction separately and then averages these accuracies.This approach provides a more nuanced evaluation of the model's performance,as it considers the accuracy of each prediction independently. For instance,if a model makes three predictions [1, 0, 1], [0, 1, 0], and [1, 1, 1],and the true values are [1, 0, 0], [0, 1, 1], and [1, 1, 1], respectively,the average accuracy would be calculated by averaging the accuracies of these individual predictions. This allows for a more granular assessmentof the model's performance across multiple predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a78dda6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_average_accuracy(binary_predictions, y):\n",
    "    \"\"\"\n",
    "    Calculate accuracy between binary predictions and true values.\n",
    "\n",
    "    Args:\n",
    "        binary_predictions (list of arrays): List of binary predictions.\n",
    "        y (list of arrays): List of true values.\n",
    "\n",
    "    Returns:\n",
    "        float: Average accuracy.\n",
    "    \"\"\"\n",
    "    accuracies = []\n",
    "\n",
    "    for i in range(len(binary_predictions)):\n",
    "        # Convert to numpy arrays if not already\n",
    "        binary_prediction_arr = np.array(binary_predictions[i])\n",
    "        y_arr = np.array(y[i])\n",
    "        \n",
    "        # Check if the elements are equal\n",
    "        accuracy = np.mean(binary_prediction_arr == y_arr)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "    # Calculate average accuracy\n",
    "    average_accuracy = np.mean(accuracies)\n",
    "    \n",
    "    return average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e1bba331",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_accuracy=calculate_average_accuracy(binary_predictions,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "439a29f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.843482905982906"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
